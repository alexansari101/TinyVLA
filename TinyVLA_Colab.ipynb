{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# TinyVLA: Fast-Iteration VLA Training on Colab\n\nTrain a minimal Vision-Language-Action model in 1-3 minutes on free Colab GPU!\n\n**What you'll learn:**\n- VLA architecture basics (ViT + Transformer + Action head)\n- Fast iteration techniques\n- Synthetic dataset generation\n\n**Runtime:** Make sure to enable GPU: Runtime → Change runtime type → GPU (T4)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision transformers matplotlib tqdm tensorboard pillow\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Code Files\n",
    "\n",
    "Upload these files to Colab:\n",
    "- `tiny_vla_dataset.py`\n",
    "- `tiny_vla_model.py`\n",
    "- `train_tiny_vla.py`\n",
    "- `inference_tiny_vla.py`\n",
    "\n",
    "Or run the cells below if you have them in your current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Clone from GitHub if you've uploaded there\n",
    "# !git clone https://github.com/your-username/tiny-vla.git\n",
    "# %cd tiny-vla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Setup Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports and setup\n",
    "from tiny_vla_dataset import BlockFindDataset\n",
    "from tiny_vla_model import create_tiny_vla\n",
    "\n",
    "# Create a small test dataset\n",
    "print(\"Creating test dataset...\")\n",
    "test_dataset = BlockFindDataset(num_samples=10)\n",
    "\n",
    "# Visualize a sample\n",
    "test_dataset.visualize_sample(0)\n",
    "\n",
    "# Display the image\n",
    "from IPython.display import Image, display\n",
    "display(Image('sample_visualization.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and inspect model\n",
    "print(\"Creating TinyVLA model...\")\n",
    "model = create_tiny_vla()\n",
    "\n",
    "# Test forward pass\n",
    "batch_size = 4\n",
    "images = torch.randn(batch_size, 3, 64, 64)\n",
    "instructions = [\n",
    "    \"Push the red block up\",\n",
    "    \"Move blue block left\",\n",
    "    \"Push green block down\",\n",
    "    \"Move yellow block right\"\n",
    "]\n",
    "\n",
    "images, input_ids, attention_mask = model.prepare_inputs(images, instructions)\n",
    "\n",
    "with torch.no_grad():\n",
    "    actions = model(images, input_ids, attention_mask)\n",
    "\n",
    "print(f\"\\nForward pass successful!\")\n",
    "print(f\"Action predictions shape: {actions.shape}\")\n",
    "print(f\"Sample prediction: {actions[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Training\n\nTrain the model for 20 epochs (1-3 minutes on T4 GPU)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Run training script directly\n",
    "!python train_tiny_vla.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Train inline with custom config (faster for prototyping)\n",
    "from train_tiny_vla import TinyVLATrainer\n",
    "from tiny_vla_dataset import create_dataloaders\n",
    "from tiny_vla_model import create_tiny_vla\n",
    "\n",
    "# Create model\n",
    "model = create_tiny_vla()\n",
    "\n",
    "# Create dataloaders (smaller dataset for faster iteration)\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_size=4000,  # Reduce for faster training\n",
    "    val_size=500,\n",
    "    test_size=500,\n",
    "    batch_size=64,\n",
    "    num_workers=2  # Colab has limited CPU\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainer = TinyVLATrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train(num_epochs=10)  # Reduce epochs for faster testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model and visualize predictions\n",
    "from inference_tiny_vla import TinyVLAInference\n",
    "from tiny_vla_dataset import BlockFindDataset\n",
    "\n",
    "# Create inference object\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "inference = TinyVLAInference('checkpoints/best_model.pt', device=device)\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = BlockFindDataset(num_samples=1000, seed=44)\n",
    "\n",
    "# Visualize predictions\n",
    "inference.visualize_predictions(test_dataset, num_samples=8)\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "display(Image('predictions.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "metrics = inference.evaluate_accuracy(test_dataset, num_samples=1000)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final Test Results\")\n",
    "print(\"=\"*50)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key:30s}: {value:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demo\n",
    "\n",
    "Test the model on individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick a random sample\n",
    "idx = np.random.randint(len(test_dataset))\n",
    "sample = test_dataset[idx]\n",
    "\n",
    "# Get prediction\n",
    "image = sample['image']\n",
    "instruction = sample['instruction']\n",
    "action_gt = sample['action'].numpy()\n",
    "action_pred = inference.predict(image, instruction)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "image_display = image.permute(1, 2, 0).numpy()\n",
    "ax.imshow(image_display)\n",
    "ax.set_title(\n",
    "    f\"Instruction: {instruction}\\n\"\n",
    "    f\"Ground Truth: [{action_gt[0]:.2f}, {action_gt[1]:.2f}]\\n\"\n",
    "    f\"Prediction: [{action_pred[0]:.2f}, {action_pred[1]:.2f}]\\n\"\n",
    "    f\"Error: {np.linalg.norm(action_pred - action_gt):.3f}\",\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# Draw arrows\n",
    "center_x, center_y = 32, 32\n",
    "arrow_scale = 15\n",
    "\n",
    "# Ground truth (green)\n",
    "ax.arrow(center_x, center_y, action_gt[0]*arrow_scale, action_gt[1]*arrow_scale,\n",
    "         head_width=3, head_length=3, fc='green', ec='green', linewidth=3, label='GT')\n",
    "\n",
    "# Prediction (red)\n",
    "ax.arrow(center_x, center_y, action_pred[0]*arrow_scale, action_pred[1]*arrow_scale,\n",
    "         head_width=3, head_length=3, fc='red', ec='red', linewidth=3, linestyle='--', label='Pred')\n",
    "\n",
    "ax.legend()\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInstruction: {instruction}\")\n",
    "print(f\"Ground Truth Action: {action_gt}\")\n",
    "print(f\"Predicted Action: {action_pred}\")\n",
    "print(f\"L2 Error: {np.linalg.norm(action_pred - action_gt):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Trained Model\n",
    "\n",
    "Download your trained model to use locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download checkpoint\n",
    "files.download('checkpoints/best_model.pt')\n",
    "\n",
    "# Download training logs\n",
    "!zip -r logs.zip logs/\n",
    "files.download('logs.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments to Try\n",
    "\n",
    "### 1. Architecture Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try smaller model (faster training)\n",
    "config_small = {\n",
    "    'image_size': 64,\n",
    "    'vision_embed_dim': 128,  # Reduced from 192\n",
    "    'vision_layers': 2,       # Reduced from 4\n",
    "    'lang_embed_dim': 128,    # Reduced from 256\n",
    "    'lang_layers': 2,         # Reduced from 4\n",
    "    'action_dim': 2,\n",
    "}\n",
    "\n",
    "model_small = create_tiny_vla(config_small)\n",
    "# ... train and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on different dataset sizes\n",
    "for train_size in [500, 1000, 2000, 4000, 8000]:\n",
    "    print(f\"\\nTraining on {train_size} samples...\")\n",
    "    # ... create dataloaders and train\n",
    "    # Compare final validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Scale up**: Increase model size gradually\n",
    "2. **Real data**: Replace synthetic data with real robot demonstrations\n",
    "3. **Pretrained models**: Use SigLip + Phi-2 backbones\n",
    "4. **Advanced techniques**: Try LoRA, cross-attention, diffusion policies\n",
    "\n",
    "Check the README for more details!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}